\begin{homeworkProblem} %Bounding Recurrences

Time complexity is asymptotic. So, considering when $n\rightarrow \infty$, we need require ``$N \geq n_0$'', which means time complexity is always stable for all values after $n_0$.
\end{homeworkProblem}

\begin{homeworkProblem}
According to the definition of Big $\mathcal{O}$, $T(N) = \mathcal{O}(f(N))$ means that $T(N) \leq cf(N)$ for some constant $c$ and for $N \geq n_0$, and $f_1(N) = 2N \leq cN$, $f_2(N) = 3N \leq cN$ for some constant $c$ (e.g. $c = 4$) when $N \geq 1$. So, they are both $\mathcal{O}(N)$.
\end{homeworkProblem}

\begin{homeworkProblem}

\begin{homeworkSubProblem}
$f_1(5) = 10, f_2(5) = 15, f_1(10) = 20, f_2(10) = 30$, When $N$ was doubled in each case, the result became double.
\end{homeworkSubProblem}

\begin{homeworkSubProblem}
$f_1(5) = 50, f_2(5) = 75, f_1(10) = 200, f_2(10) = 300,$ When $N$ was doubled in each case, the result became quadruple.
\end{homeworkSubProblem}
\end{homeworkProblem}

\begin{homeworkProblem}
Algorithm analysis is dedicated to understanding the complexity of algorithms that could be expressed by Big-$\mathcal{O}$. And Assume two functions $f(N)$ and $g(N)$ are considered as two algorithms, as the scale of the problem(N) increases, $\mathcal{O}(f(N))$ and $\mathcal{O}(g(N))$ are their own growth rates of algorithm execution time. In the meantime, if there exists $\mathcal{O}(f(N)) < \mathcal{O}(g(N))$, which means complexity of algorithm $g(N)$ is more than complexity of algorithm $f(N)$. So Big-$\mathcal{O}$ could be applicable to algorithms analysis.
\end{homeworkProblem}

\begin{homeworkProblem}
$n!$ grows faster.

\begin{proof}

\BaseCase $n = 4, 2^4=16 < 4!=24$, So, it is true for $n = 4$.

\InductionStep Assume it is true for $k$, that $2^k < k!$.

Show true for $k+1$:
\begin{equation*}
\begin{split}
2^{(k+1)} & = 2^k \times 2\\
(k+1)!  & = k! \times (k+1)\\
\end{split}
\end{equation*}
Due to $2^k < k!$ and $2 < k+1$, so $2^{(k+1)} < (k+1)!$

Conclusion:  by induction, the statement holds true for all $n \geq 4$.
So $n!$ grows faster.
\end{proof}
\end{homeworkProblem}

\begin{homeworkProblem}
\begin{enumerate}[label=(\alph*)]
\item $\mathcal{O}(n^5)$

\item $\mathcal{O}(5^n)$

\item $\mathcal{O}(n)$

\item $\mathcal{O}(n\log(n))$

\item $\mathcal{O}(n^2)$
\end{enumerate}
\end{homeworkProblem}

\begin{homeworkProblem}
i=0, i $<$ numItems; i++;  // $1 + (n+1) + n$

$1 + (n+1) + n = 2n + 2$, so the result is $\mathcal{O}(n)$.
\end{homeworkProblem}

\begin{homeworkProblem}
i=0; i$<$numItems; i++;   // $1 + (n+1) + n$

j=0; j$<$numItems; j++;   // $n(1 + (n+1) + n)$

(i+1) * (j+1);              // $n\times n\times 3$

// $1 + (n+1) + n + n(1 + (n+1) + n) + n\times n\times 3 = 5n^2 + 4n + 2$, so the result is $\mathcal{O}(n^2)$.
\end{homeworkProblem}

\begin{homeworkProblem}
i=0; i$<$numItems+1; i++;    // $1 + (n+2) + (n+1)$

j=0; j$<$2*numItems; j++;    // $(n+1)(1 + (2n+1) + 2n)$

(i+1) * (j+1);             // $(n+1)\times 2n\times 3$

// $1 + (n+2) + (n+1) + (n+1)(1 + (2n+1) + 2n) +(n+1)\times 2n\times 3 = 10n^2 + 14n + 6$, so the result is $\mathcal{O}(n^2)$.
\end{homeworkProblem}

\begin{homeworkProblem}
When num $<$ numItems:

num $<$ numItems;            // $1$

int i=0; i $<$ numItems; i++;  // $1 + (n+1) + n$

System.out.println(i);                         // $n$

$1 + 1 + (n+1) + n + n = 3n + 3$, so the result is $\mathcal{O}(n)$.

When num $>$ numItems:

``too many'';              // $1$

So the result is $\mathcal{O}(1)$.
\end{homeworkProblem}

\begin{homeworkProblem}
i = numItems;         // $1$

i $>$ 0;                // $\lg n +1$

i = i / 2;            // $\lg n$

$1 + \lg n + 1 + \lg n = 2 + 2\lg n$, so the result is $\mathcal{O}(\lg n)$.
\end{homeworkProblem}

\begin{homeworkProblem}{}
numItems == 0;           // $1 + \lg n$

return 0ï¼›               // $1$

numItems\%2 + div(numItems/2)   // $2\lg n$

$1 + \lg n + 1 + 2\lg n = 3\lg n + 2$, so the result is $\mathcal{O}(\lg n)$.
\end{homeworkProblem}
